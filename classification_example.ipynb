{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from ml2sql import ML2SQL\n",
    "\n",
    "# PostgreSQL\n",
    "import psycopg2 as pg\n",
    "con = pg.connect(CONNECTIONSTRING)\n",
    "backend = \"postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query, con, should_print = True):\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(query)\n",
    "    rs = cursor.fetchall()\n",
    "    if not rs:\n",
    "        print(\"Query result is empty\")\n",
    "    colnames = [desc[0] for desc in cursor.description]\n",
    "    if should_print:\n",
    "        print(colnames)\n",
    "        for res in rs:\n",
    "            print(res)\n",
    "    cursor.close()\n",
    "\n",
    "def run_update_query(query, con):\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(query)\n",
    "    con.commit()\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(4,),activation='linear', bias_initializer=tf.keras.initializers.RandomNormal()),\n",
    "    tf.keras.layers.Dense(8, input_shape=(4,),activation='relu', bias_initializer=tf.keras.initializers.RandomNormal()),\n",
    "    tf.keras.layers.Dense(2, input_shape=(4,),activation='sigmoid', bias_initializer=tf.keras.initializers.RandomNormal()),\n",
    "    tf.keras.layers.Dense(1, activation='linear', bias_initializer=tf.keras.initializers.RandomNormal())\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize ml2sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = ML2SQL(con, backend, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_table_name = \"iris_model\"\n",
    "start_time = time.time()\n",
    "queries = translator.model_to_relation(model_table_name)\n",
    "for q in queries:\n",
    "    run_update_query(q, con)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "q = f\"select * from {model_table_name}\"\n",
    "#run_query(q, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table has to exist in database\n",
    "tablename = \"iris\"\n",
    "id_col_name = \"id\"\n",
    "col_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "output_col_name = \"prediction\"\n",
    "\n",
    "# Build MJ query\n",
    "input_query = f\"Select * from {tablename}\"\n",
    "mj_query = translator.model_join_query(input_query, id_col_name, col_names, model_table_name, output_col_name)\n",
    "# Run MJ\n",
    "start_time = time.time()\n",
    "run_query(mj_query, con, False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cols = ','.join(col_names)\n",
    "query = f\"Select id, {cols}, {output_col_name} from ({mj_query}) as t order by id\"\n",
    "\n",
    "cursor = con.cursor()\n",
    "cursor.execute(query)\n",
    "rs = cursor.fetchall()\n",
    "\n",
    "arr = np.array(rs, dtype='float32')[:,1:] # drop the id col\n",
    "splitted = np.hsplit(arr, [len(col_names)])\n",
    "inputs = splitted[0]\n",
    "\n",
    "# Do inference with TensorFlow\n",
    "start_time = time.time()\n",
    "tfpred = model.predict(inputs)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float precision and representation is different, so convert to ints\n",
    "# TODO: categorical values\n",
    "#predictions = (splitted[1] * 1000000).astype(int)\n",
    "#model_out = (model.predict(inputs) * 1000000).astype(int)\n",
    "decimals = 5\n",
    "predictions = splitted[1].round(decimals)\n",
    "model_out = tfpred.round(decimals)\n",
    "\n",
    "if not np.array_equal(predictions, model_out):\n",
    "\tprint(\"Results not verified!\")\n",
    "\t#print(np.equal(predictions, model_out))\n",
    "\n",
    "\tfor idx, el in np.ndenumerate(predictions):\n",
    "\t\tif np.not_equal(el, model_out[idx]) and el != model_out[idx]:\n",
    "\t\t\tprint(idx[0], el, model_out[idx])\n",
    "else:\n",
    "\tprint(\"Results verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "171ca16dd172dc2b3cdeafc1ce1ce1457c8e5ff5a50b1d68672fa0255e596485"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
